import { useState } from 'react';
import { ChatSession, ChatMessage } from '../../types';
import { ChatMessageData } from '../../utils/gemini';

interface UseCordGenerationProps {
    lang: 'ja' | 'en';
    sessions: ChatSession[];
    messages: ChatMessage[];
    addMessage: (role: 'user' | 'ai' | 'system' | 'function', content: string, sessionIdOverride?: string, functionCall?: any, rawParts?: any[], thoughtSummary?: string) => string;
    cordDebug: {
        setCordDebugSystemPrompt: (v: string) => void;
        setCordDebugInputText: (v: string) => void;
        setCordDebugMatchedEntities: (v: any[]) => void;
    };
    STORAGE_KEY_SESSIONS: string;
    STORAGE_KEY_MESSAGES_PREFIX: string;
    saveSessionsToStorage: (updatedSessions: ChatSession[]) => void;
    triggerAutoHistory?: () => void;
    triggerWombGeneration?: (blueprintOverride?: string) => Promise<void>;
    cordOutputLength: number;
    checkIsBackgroundProcessing?: () => boolean;
}

export const useCordGeneration = ({
    lang,
    sessions,
    messages,
    addMessage,
    cordDebug,
    STORAGE_KEY_SESSIONS,
    STORAGE_KEY_MESSAGES_PREFIX,
    saveSessionsToStorage,
    triggerAutoHistory,
    triggerWombGeneration,
    cordOutputLength,
    checkIsBackgroundProcessing
}: UseCordGenerationProps) => {
    const [isTyping, setIsTyping] = useState<boolean>(false);
    const [isStreaming, setIsStreaming] = useState<boolean>(false);
    const [streamingText, setStreamingText] = useState<string>('');
    const [streamingThought, setStreamingThought] = useState<string>('');

    // Action: Generate AI Response
    const generateAiResponse = async (
        sessionId: string,
        apiKey: string,
        novelAIApiKey: string,
        aiModel: 'gemini-2.5-flash' | 'gemini-3.1-pro-preview' | 'glm-4-6',
        getWombContext?: () => Promise<{ systemInstruction: string, entityContext?: string, scanTargetContent?: string, matchedLoreItems: any[], allActiveLoreItems: any[], allLoreItems: any[], cleanedContent: string, storyTitle: string }>
    ) => {
        if (!apiKey && !novelAIApiKey) {
            // Fallback mock if no API key
            setIsTyping(true);
            setTimeout(() => {
                const responseText = lang === 'ja'
                    ? '„Å™„Çã„Åª„Å©„ÄÅ„Åù„Çå„ÅØËààÂë≥Ê∑±„ÅÑ„Åß„Åô„Å≠„ÄÇÔºà‚ÄªAPI„Ç≠„Éº„ÅåÊú™Ë®≠ÂÆö„ÅÆ„Åü„ÇÅ„É¢„ÉÉ„ÇØÂøúÁ≠î„Åß„ÅôÔºâ'
                    : 'I see, that sounds interesting. (Mock response due to missing API key)';
                addMessage('ai', responseText, sessionId);
                setIsTyping(false);
            }, 1000);
            return;
        }

        setIsTyping(true);
        try {
            const { callGeminiChatStream, callGemini } = await import('../../utils/gemini');

            // Get latest messages for this session from state/localStorage
            const storedMessages = localStorage.getItem(STORAGE_KEY_MESSAGES_PREFIX + sessionId);
            const currentMessages: ChatMessage[] = storedMessages ? JSON.parse(storedMessages) : messages;

            const freshSessionsStrForCheck = localStorage.getItem(STORAGE_KEY_SESSIONS);
            const freshCurrentSessions: ChatSession[] = freshSessionsStrForCheck ? JSON.parse(freshSessionsStrForCheck) : sessions;
            const currentSession = freshCurrentSessions.find(s => s.id === sessionId);

            const sessionLang = currentSession?.aiLang || lang;

            let systemPrompt = sessionLang === 'ja'
                ? `„ÅÇ„Å™„Åü„ÅØËÉΩÂãïÁöÑÁâ©Ë™ûÂàÜÊûêAI„ÄåCORD„Äç„Åß„Åô„ÄÇ„É¶„Éº„Ç∂„Éº„ÅÆÂü∑Á≠Ü„ÇÑ„Ç¢„Ç§„Éá„Ç¢Âá∫„Åó„Çí„Çµ„Éù„Éº„Éà„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
ÈáçË¶Å„Å™ÂΩπÂâ≤„Å®„Åó„Å¶„ÄÅWOMBÔºàÂü∑Á≠ÜAIÔºâ„Å´Á∂ö„Åç„ÇíÊõ∏„Åã„Åõ„Çã„Åü„ÇÅ„ÅÆ„ÄåNarrative BlueprintÔºàÂ±ïÈñãÊåáÁ§∫Êõ∏Ôºâ„Äç„ÅÆ‰ΩúÊàê„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ
Ëá™ÂãïÁîüÊàê„ÇíÊ±Ç„ÇÅ„Çâ„Çå„ÅüÂ†¥Âêà„ÅØ„ÄÅÂøÖ„Åö‰ª•‰∏ã„ÅÆË¶Å‰ª∂„Å®„Éï„Ç©„Éº„Éû„ÉÉ„Éà„ÇíÊ∫Ä„Åü„Åó„ÅüNarrative Blueprint„Çí‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

„ÄêNarrative Blueprint „ÅÆË¶Å‰ª∂„Äë
- ÁèæÁä∂„ÅÆÁ∞°Âçò„Å™ÂàÜÊûê„Å®Ë¶ÅÁ¥Ñ
- Ê¨°„ÅÆ„Ç∑„Éº„É≥„ÅßÈÅîÊàê„Åô„Åπ„ÅçÁõÆÁöÑÔºàMust-haveÔºâ
- ÁôªÂ†¥‰∫∫Áâ©„ÅÆÊÑüÊÉÖ„ÅÆÂãï„Åç„Å®„Ç¢„ÇØ„Ç∑„Éß„É≥
- „Çª„É™„Éï„ÅÆ„Éà„Éº„É≥„ÇÑÊèèÂÜô„ÅÆ„ÉÜ„Ç§„Çπ„ÉàË®≠ÂÆö
- Narrative Blueprint„ÇíÁîüÊàê„Åô„ÇãÈöõ„ÅØ„ÄÅtrigger_womb_generation„ÉÑ„Éº„É´„ÅÆÂºïÊï∞„ÅÆ„Åø„Å´Narrative Blueprint„ÇíÊ∏°„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ„É¶„Éº„Ç∂„Éº„Å∏„ÅÆËøîÁ≠î„ÉÜ„Ç≠„Çπ„Éà„Å´„ÅØBlueprint„ÅÆÂÜÖÂÆπ„ÇíÂê´„ÇÅ„Å™„ÅÑ„Åß„Åè„Å†„Åï„ÅÑ„ÄÇ
- „ÉÑ„Éº„É´Âëº„Å≥Âá∫„Åó„ÅåÊàêÂäü„Åó„ÅüÂæå„ÅØ„ÄÅ„É¶„Éº„Ç∂„Éº„Å∏„ÅÆËøîÁ≠î„Å®„Åó„Å¶„ÄåWOMB„ÅßÁîüÊàê„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„Äç„Å™„Å©„ÅÆÁü≠„ÅÑÂÆå‰∫ÜÂ†±Âëä„ÅÆ„Åø„Çí„ÉÜ„Ç≠„Çπ„ÉàÂá∫Âäõ„Åó„Å¶ÂõûÁ≠î„ÇíÁµÇ‰∫Ü„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÂêå„Åò„ÉÑ„Éº„É´„ÇíË§áÊï∞ÂõûÂëº„Å∞„Å™„ÅÑ„Åß„Åè„Å†„Åï„ÅÑ„ÄÇ`
                : `You are the Active Story Analysis AI, "CORD". Support the user's writing and brainstorming.
An important role of yours is to create a "Narrative Blueprint" for WOMB (the writing AI) to write the continuation.
When auto-generation is requested, you MUST create a Narrative Blueprint that meets the following requirements and format.

[Narrative Blueprint Requirements]
- Provide a brief analysis and summary of the current situation.
- The objective that must be achieved in the next scene (Must-have).
- The character's emotional movements and actions.
- The tone of the dialogue and the taste of the description.
- When generating a Narrative Blueprint, pass the Narrative Blueprint ONLY to the arguments of the trigger_womb_generation tool. Do not include the contents of the Narrative Blueprint in the response text.
- After the tool call is successful, output a short confirmation text like "Started generation in WOMB" and finish your response. Do not call the same tool multiple times in a row.`;

            let wombContextString = "";
            if (currentSession?.isAwareOfWombStory && getWombContext) {
                try {
                    const wombContext = await getWombContext();
                    if (wombContext) {
                        wombContextString += `[System Info: Current WOMB Story Context]\n`;
                        if (wombContext.entityContext) {
                            wombContextString += `--- Matched Entities ---\n${wombContext.entityContext}\n\n`;
                        }

                        if (wombContext.cleanedContent) {
                            wombContextString += `--- Story Body Text ---\n${wombContext.cleanedContent}`;
                        }

                        // Set matched entities for debug panel
                        cordDebug.setCordDebugMatchedEntities(wombContext.matchedLoreItems || []);
                    }
                } catch (e) {
                    console.error("Failed to load WOMB context for CORD", e);
                }
            }

            // Assemble final array for API call
            const apiMessages = [...currentMessages];
            if (wombContextString && apiMessages.length > 0) {
                // Find the last user message and prepend the context to it, keeping the user input at the very end
                for (let i = apiMessages.length - 1; i >= 0; i--) {
                    if (apiMessages[i].role === 'user') {
                        const originalInput = apiMessages[i].content;

                        // Construct Output Length Constraint for CORD
                        const lengthConstraint = sessionLang === 'ja'
                            ? `\n\n„ÄêÂá∫ÂäõÂΩ¢Âºè„ÅÆÂà∂Á¥Ñ„Äë\n„ÅÇ„Å™„Åü„ÅÆËøîÁ≠î„ÉÜ„Ç≠„Çπ„Éà„ÅØ„ÄÅÂÖ®‰Ωì„ÅßÂ§ß‰Ωì ${cordOutputLength} ÊñáÂ≠ó‰ª•ÂÜÖ„Å´„Å™„Çã„Çà„ÅÜ„Å´Ë™øÊï¥„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ`
                            : `\n\n[Output Constraints]\nAdjust the character count of your response to be roughly within ${cordOutputLength} characters.`;

                        const userInputHeader = `${lengthConstraint}\n\n=== User Input ===\n`;

                        apiMessages[i] = {
                            ...apiMessages[i],
                            content: wombContextString + userInputHeader + originalInput
                        };
                        break;
                    }
                }
            }

            // Define tools for CORD
            const cordTools = [{
                functionDeclarations: [{
                    name: "search_web",
                    description: sessionLang === 'ja'
                        ? "ÊúÄÊñ∞„ÅÆÊÉÖÂ†±„ÇíGoogle„ÅßÊ§úÁ¥¢„Åó„Åæ„Åô„ÄÇ‰∫ãÂÆüÁ¢∫Ë™ç„ÅåÂøÖË¶Å„Å™Â†¥Âêà„Å´‰ΩøÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
                        : "Searches Google for up-to-date information. Use this when you need to verify facts.",
                    parameters: {
                        type: "OBJECT",
                        properties: {
                            query: {
                                type: "STRING",
                                description: sessionLang === 'ja' ? "Ê§úÁ¥¢„ÇØ„Ç®„É™Ôºà‰æã: 'ÊúÄÊñ∞„ÅÆAI „Éã„É•„Éº„Çπ'Ôºâ" : "The search query."
                            }
                        },
                        required: ["query"]
                    }
                }, {
                    name: "insert_womb_instruction",
                    description: sessionLang === 'ja'
                        ? "WOMB„ÅÆ„Ç®„Éá„Ç£„Çø„ÅÆÁèæÂú®„ÅÆ„Ç´„Éº„ÇΩ„É´‰ΩçÁΩÆ„Å´„ÄÅÊåáÂÆö„Åó„ÅüAI„Ç§„É≥„Çπ„Éà„É©„ÇØ„Ç∑„Éß„É≥„ÇíÊåøÂÖ•„Åó„Åæ„Åô„ÄÇ„É¶„Éº„Ç∂„Éº„ÅÆ‰ª£„Çè„Çä„Å´ÊåáÁ§∫„ÇíÊõ∏„ÅçËæº„ÇÄÈöõ„Å´‰ΩøÁî®„Åó„Åæ„Åô„ÄÇ"
                        : "Inserts the specified AI instruction at the current cursor position in the WOMB editor. Use this to write instructions on behalf of the user.",
                    parameters: {
                        type: "OBJECT",
                        properties: {
                            instruction_text: {
                                type: "STRING",
                                description: sessionLang === 'ja' ? "ÊåøÂÖ•„Åô„ÇãÂÖ∑‰ΩìÁöÑ„Å™ÊåáÁ§∫Êñá„ÄÇ" : "The specific instruction text to insert."
                            }
                        },
                        required: ["instruction_text"]
                    }
                }, {
                    name: "add_womb_history",
                    description: sessionLang === 'ja'
                        ? "„É¶„Éº„Ç∂„Éº„Åã„ÇâÊòéÁ¢∫„Å™ÊåáÁ§∫„Åå„ÅÇ„Å£„ÅüÂ†¥Âêà„ÅÆ„Åø‰ΩøÁî®„Åó„Åæ„Åô„ÄÇÂØæË±°„ÅÆ„Ç≠„É£„É©„ÇØ„Çø„Éº(Entity)„ÅÆHistory„Å´Âá∫Êù•‰∫ã„ÇÑÊÉÖÂ†±„ÇíËøΩË®ò„Åó„Åæ„Åô„ÄÇÂØæË±°„Åå‰∏ÄÊÑè„Å´ÂÆö„Åæ„Çâ„Å™„ÅÑÂ†¥Âêà„ÅØ„Ç∑„Çπ„ÉÜ„É†„Åã„ÇâÂÄôË£ú„ÅåËøî„Åï„Çå„Çã„ÅÆ„Åß„ÄÅ„É¶„Éº„Ç∂„Éº„Å´Ë≥™Âïè„Åó„Å¶ÂØæË±°„ÅÆID„ÇíÁµû„ÇäËæº„Çì„Åß„Åè„Å†„Åï„ÅÑ„ÄÇ"
                        : "Use ONLY when explicitly instructed by the user. Adds a new event to the History of the target character. If the target is ambiguous, candidates will be returned to you so you can ask the user to clarify the ID.",
                    parameters: {
                        type: "OBJECT",
                        properties: {
                            entity_query: {
                                type: "STRING",
                                description: sessionLang === 'ja' ? "„É¶„Éº„Ç∂„Éº„ÅåÊåáÂÆö„Åó„ÅüÂØæË±°„Ç≠„É£„É©„ÇØ„Çø„Éº„ÅÆÂêçÂâç„ÇÑ„Ç≠„Éº„ÉØ„Éº„Éâ„ÄÇ" : "The Name or keyword of the target character specified by the user."
                            },
                            entity_id: {
                                type: "STRING",
                                description: sessionLang === 'ja' ? "ÂØæË±°„ÇíÂÆåÂÖ®„Å´ÁâπÂÆö„Åß„Åç„Å¶„ÅÑ„ÇãÂ†¥Âêà(„É¶„Éº„Ç∂„Éº„Åã„ÇâID„ÇíÊåáÂÆö„Åï„Çå„ÅüÁ≠â)„ÅÆ„Ç∑„Çπ„ÉÜ„É†ID„ÄÇ‰∏çÊòé„Å™Â†¥Âêà„ÅØÁúÅÁï•„ÄÇ" : "The system ID of the character if uniquely identified. Omit if unsure."
                            },
                            history_text: {
                                type: "STRING",
                                description: sessionLang === 'ja' ? "History„Å´ËøΩË®ò„Åô„ÇãÊÉÖÂ†±„ÄÇ" : "The information to append to the History."
                            }
                        },
                    }
                }, {
                    name: "trigger_auto_history",
                    description: sessionLang === 'ja'
                        ? "„É¶„Éº„Ç∂„Éº„Åã„Çâ„Äå‰ªä„ÅÆÊú¨Êñá„Åã„Çâ„Éí„Çπ„Éà„É™„Éº„ÇíÊäΩÂá∫„Åó„Å¶„Äç„ÄåÊúÄÊñ∞„ÅÆÊµÅ„Çå„ÇíÊõ¥Êñ∞„Åó„Å¶„Äç„ÅÆ„Çà„ÅÜ„Å´Ëá™ÂãïÊäΩÂá∫„Çí‰æùÈ†º„Åï„Çå„ÅüÂ†¥Âêà„Å´‰ΩøÁî®„Åó„Åæ„Åô„ÄÇÂÜÖÈÉ®„ÅßÊú¨Êñá„ÅÆÂ∑ÆÂàÜËß£Êûê„Éó„É≠„Çª„Çπ„ÇíÂº∑Âà∂Ëµ∑Âãï„Åó„ÄÅÂØæË±°„Ç≠„É£„É©„ÇØ„Çø„Éº„ÅÆHistory„ÇíËá™ÂãïÊõ¥Êñ∞„Åï„Åõ„Åæ„Åô„ÄÇ"
                        : "Use this when the user requests to automatically extract or record history from the current text. It manually triggers the background diff-analysis process to update character histories.",
                    parameters: {
                        type: "OBJECT",
                        properties: {}
                    }
                }, {
                    name: "trigger_womb_generation",
                    description: sessionLang === 'ja'
                        ? "„É¶„Éº„Ç∂„Éº„Åã„Çâ„ÄåÁ∂ö„Åç„ÇíÊõ∏„ÅÑ„Å¶„Äç„Äå„Äá„Äá„ÅÆÂ±ïÈñã„ÇíÁîüÊàê„Åó„Å¶„Äç„ÅÆ„Çà„ÅÜ„Å´„ÄÅWOMB(Âü∑Á≠ÜAI)„Å´„Çà„ÇãÊú¨Êñá„ÅÆËá™ÂãïÁîüÊàê„Çí‰æùÈ†º„Åï„Çå„ÅüÂ†¥Âêà„Å´‰ΩøÁî®„Åó„Åæ„Åô„ÄÇ„Åì„Çå„ÇíÂëº„Å≥Âá∫„Åô„Å®„ÄÅ„ÅÇ„Å™„Åü„Åå‰ΩúÊàê„Åó„ÅüÂàÜÊûê„ÉªÊåáÁ§∫(Narrative Blueprint)„Å´Âü∫„Å•„ÅÑ„Å¶WOMB„ÅåÂ∞èË™¨„ÅÆÁ∂ö„Åç„ÇíÂü∑Á≠Ü„Åó„Åæ„Åô„ÄÇ"
                        : "Use this when the user asks you to 'write the continuation' or 'generate the next part'. Calling this will trigger the WOMB (Writing AI) to write the next part of the novel based on your analysis and instructions (Narrative Blueprint).",
                    parameters: {
                        type: "OBJECT",
                        properties: {
                            blueprint_text: {
                                type: "STRING",
                                description: sessionLang === 'ja' ? "WOMB„Å´Ê∏°„Åô„Åü„ÇÅ„ÅÆNarrative Blueprint„ÅÆ„ÉÜ„Ç≠„Çπ„ÉàÂÖ®Êñá" : "The full text of the Narrative Blueprint to pass to WOMB"
                            }
                        },
                        required: ["blueprint_text"]
                    }
                }]
            }]; // Notice: googleSearch is deliberately omitted to prevent API 400 errors

            // [HACK] For GLM-4 model which ignores tool definitions in the system param,
            // we manually append the tool descriptions and formatting rules into the system prompt.
            if (aiModel === 'glm-4-6') {
                systemPrompt += `\n\n„ÄêÈáçË¶Å: „ÉÑ„Éº„É´„ÅÆ‰ΩøÁî®„Å®Âá∫Âäõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„ÅÆÂé≥ÂÆà„Äë
„ÅÇ„Å™„Åü„ÅØÁèæÂú®„ÅÆÁí∞Â¢É„Å´„Åä„ÅÑ„Å¶„ÄÅËøΩÂä†„Åß‰ª•‰∏ã„ÅÆ3„Å§„ÅÆ„ÉÑ„Éº„É´„Çí‰ΩøÁî®„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÄÇ

- ÂêçÂâç: "insert_womb_instruction"
- ÁõÆÁöÑ: WOMB„ÅÆ„Ç®„Éá„Ç£„Çø„ÅÆÁèæÂú®„ÅÆ„Ç´„Éº„ÇΩ„É´‰ΩçÁΩÆ„Å´„ÄÅÊåáÂÆö„Åó„ÅüAI„Ç§„É≥„Çπ„Éà„É©„ÇØ„Ç∑„Éß„É≥„ÇíÊåøÂÖ•„Åó„Åæ„Åô„ÄÇ„É¶„Éº„Ç∂„Éº„ÅÆ‰ª£„Çè„Çä„Å´ÊåáÁ§∫„ÇíÊõ∏„ÅçËæº„ÇÄÈöõ„Å´‰ΩøÁî®„Åó„Åæ„Åô„ÄÇ
- ÂºïÊï∞: "instruction_text" (ÊñáÂ≠óÂàó)

- ÂêçÂâç: "add_womb_history"
- ÁõÆÁöÑ: WOMB‰∏ä„ÅÆÁâπÂÆö„ÅÆ„Ç≠„É£„É©„ÇØ„Çø„ÉºÔºàEntityÔºâ„ÅÆÂ±•Ê≠¥„Å´ÊÉÖÂ†±„ÇíËøΩÂä†„Åó„Åæ„Åô„ÄÇ
- ÂºïÊï∞:
  - "entity_query" (ÊñáÂ≠óÂàó): ÂØæË±°„Ç≠„É£„É©„ÇØ„Çø„Éº„ÅÆÂêçÂâç„Åæ„Åü„ÅØ„Ç≠„Éº„ÉØ„Éº„Éâ„ÄÇ
  - "history_text" (ÊñáÂ≠óÂàó): ËøΩÂä†„Åô„ÇãÂ±•Ê≠¥„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„ÄÇ

- ÂêçÂâç: "trigger_womb_generation"
- ÁõÆÁöÑ: WOMB(Âü∑Á≠ÜAI)„Å´„Çà„ÇãÊú¨Êñá„ÅÆËá™ÂãïÁîüÊàê„Çí‰æùÈ†º„Åï„Çå„ÅüÂ†¥Âêà„Å´‰ΩøÁî®„Åó„Åæ„Åô„ÄÇ„Åì„Çå„ÇíÂëº„Å≥Âá∫„Åô„Åì„Å®„Åß„ÄÅ„ÅÇ„Å™„Åü„Åå‰ΩúÊàê„Åó„ÅüÂàÜÊûê„ÉªÂ±ïÈñãÊåáÁ§∫(Narrative Blueprint)„Å´Âü∫„Å•„ÅÑ„Å¶WOMB„ÅåÂ∞èË™¨„ÅÆÁ∂ö„Åç„ÇíÂü∑Á≠Ü„Åó„Åæ„Åô„ÄÇ
- ÂºïÊï∞:
  - "blueprint_text" (ÊñáÂ≠óÂàó): WOMB„Å´Ê∏°„Åô„Åü„ÇÅ„ÅÆNarrative Blueprint„ÅÆ„ÉÜ„Ç≠„Çπ„ÉàÂÖ®Êñá„ÄÇ

„ÉÑ„Éº„É´„Çí‰ΩøÁî®„Åô„ÇãÂ†¥Âêà„ÅØ„ÄÅ**ÂÆåÂÖ®„Å´Êé®Ë´ñ„Å®ÊñáÁ´†„ÅÆÂá∫Âäõ„ÇíÂÆå‰∫Ü„Åó„Åü„ÅÇ„Å®„ÄÅÁô∫Ë®Ä„ÅÆÊúÄÂæåÂ∞æ„Å´**‰ª•‰∏ã„ÅÆÂé≥ÂØÜ„Å™„Éï„Ç©„Éº„Éû„ÉÉ„Éà„ÅÆ„Åø„ÇíÂá∫Âäõ„Åó„ÄÅ„Äå===END_TOOL_CALL===„Äç„ÅÆÈñâ„ÅòÊñáÂ≠ó„Åæ„ÅßÂÆåÂÖ®„Å´Êõ∏„ÅçÂàá„Å£„Å¶„Åã„ÇâÁµÇ‰∫Ü„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
ÈÄî‰∏≠„ÅßÂá∫Âäõ„ÇíÂÅúÊ≠¢„Åó„Åü„Çä„ÄÅJSON„ÅÆÊßãÈÄ†„ÇíÁ†¥Â£ä„Åó„Åü„Çä„Åô„Çã„Åì„Å®„ÅØ„Ç∑„Çπ„ÉÜ„É†„Ç®„É©„Éº„Å´Áõ¥Áµê„Åô„Çã„Åü„ÇÅÁµ∂ÂØæ„Å´ÈÅø„Åë„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

[Ê≠£„Åó„ÅÑÂá∫Âäõ„ÅÆ‰æãÔºàinsert_womb_instruction„ÅÆÂ†¥ÂêàÔºâ]
„Çè„Åã„Çä„Åæ„Åó„ÅüÔºÅÊåáÁ§∫„ÇíÊåøÂÖ•„Åó„Åæ„Åô„Å≠„ÄÇ
===BEGIN_TOOL_CALL===
{"name": "insert_womb_instruction", "args": {"instruction_text": "ÊåøÂÖ•„Åó„Åü„ÅÑÊåáÁ§∫Êñá"}}
===END_TOOL_CALL===

[Ê≠£„Åó„ÅÑÂá∫Âäõ„ÅÆ‰æãÔºàadd_womb_history„ÅÆÂ†¥ÂêàÔºâ]
ÁéãÊßò„ÅÆÂ±•Ê≠¥„Å´ËøΩÂä†„Åó„Åæ„Åó„ÅüÔºÅ
===BEGIN_TOOL_CALL===
{"name": "add_womb_history", "args": {"entity_query": "ÁéãÊßò", "history_text": "Âüé„ÅÆ‰øÆÁπï„ÇíÂëΩ„Åò„Åü"}}
===END_TOOL_CALL===

[Ê≠£„Åó„ÅÑÂá∫Âäõ„ÅÆ‰æãÔºàtrigger_womb_generation„ÅÆÂ†¥ÂêàÔºâ]
ÂàÜÊûê„ÅåÁµÇ„Çè„Çä„Åæ„Åó„ÅüÔºÅ„Åì„ÅÆÂ±ïÈñãÊåáÁ§∫„ÅßWOMB„Å´ÁîüÊàê„Çí‰æùÈ†º„Åó„Åæ„Åô„Å≠„ÄÇ
===BEGIN_TOOL_CALL===
{"name": "trigger_womb_generation", "args": {"blueprint_text": "„ÄêÂâçÂõû„ÅÆ„ÅÇ„Çâ„Åô„Åò„ÄëÁéãÊßò„ÅØÂüé„Åã„ÇâËÑ±Âá∫„Åó...„Äê‰ªäÂæå„ÅÆÂ±ïÈñã„ÄëÊ£Æ„Å∏Âêë„Åã„ÅÜ‰∏ÄË°å„ÅØ..."}}
===END_TOOL_CALL===
`;
            }

            // Update Debug State visually
            let lastUserInput = "";
            for (let i = apiMessages.length - 1; i >= 0; i--) {
                if (apiMessages[i].role === 'user') {
                    lastUserInput = apiMessages[i].content;
                    break;
                }
            }
            cordDebug.setCordDebugSystemPrompt(systemPrompt);
            cordDebug.setCordDebugInputText(lastUserInput);

            // Call Chat API with Streaming, loop for multi-turn function calls
            setIsStreaming(true);
            setStreamingText('');
            setStreamingThought('');

            let currentApiMessages = [...apiMessages];
            let loopCount = 0;
            const MAX_LOOPS = 5;
            let hasTriggeredWomb = false;
            let hasTriggeredAutoHistory = false;

            try {
                while (loopCount < MAX_LOOPS) {
                    loopCount++;
                    let accumulatedText = '';
                    let accumulatedThought = '';
                    let finalFunctionCall: any = undefined;
                    let finalRawParts: any[] = [];

                    if (loopCount > 1) {
                        setIsStreaming(true);
                        setStreamingText('');
                        setStreamingThought('');
                    }

                    let abortController: AbortController | undefined;
                    let stream;
                    if (aiModel === 'glm-4-6') {
                        const { callNovelAIChatStream } = await import('../../utils/novelai');
                        abortController = new AbortController();
                        // tools are ignored in NovelAI for now
                        stream = callNovelAIChatStream(novelAIApiKey, currentApiMessages as any, aiModel, systemPrompt, abortController.signal);
                    } else {
                        stream = callGeminiChatStream(apiKey, currentApiMessages as any, aiModel as any, systemPrompt, cordTools);
                    }

                    for await (const chunk of stream) {
                        if (chunk.textChunk) {
                            accumulatedText += chunk.textChunk;
                            // Remove leading newlines/spaces that some models (like GLM) might return
                            setStreamingText(accumulatedText.trimStart());

                            // Abort streaming early if tool call block is finished
                            if (aiModel === 'glm-4-6' && accumulatedText.includes("===END_TOOL_CALL===")) {
                                if (abortController) abortController.abort();
                                break;
                            }
                        }
                        if (chunk.thoughtChunk) {
                            accumulatedThought += chunk.thoughtChunk;
                            setStreamingThought(accumulatedThought);
                        }
                        if (chunk.functionCall) {
                            finalFunctionCall = chunk.functionCall;
                        }
                        if (chunk.rawParts && chunk.rawParts.length > 0) {
                            finalRawParts = chunk.rawParts;
                        }
                    }

                    // --- Post-Streaming Async Tool Parsing (Fallback logic specifically for models without native tool call like NovelAI) ---
                    let isAsyncParsedTool = false; // Flag to stop recursive loops
                    if (!finalFunctionCall && accumulatedText) {
                        const TOOL_START_TAG = "===BEGIN_TOOL_CALL===";
                        const TOOL_END_TAG = "===END_TOOL_CALL===";
                        if (accumulatedText.includes(TOOL_START_TAG) && accumulatedText.includes(TOOL_END_TAG)) {
                            try {
                                const startIdx = accumulatedText.indexOf(TOOL_START_TAG) + TOOL_START_TAG.length;
                                const endIdx = accumulatedText.indexOf(TOOL_END_TAG, startIdx);
                                if (endIdx !== -1) {
                                    let jsonStr = accumulatedText.substring(startIdx, endIdx).trim();
                                    jsonStr = jsonStr.replace(/\n/g, "\\n").replace(/\r/g, "\\r");
                                    jsonStr = jsonStr.replace(/^```json/g, "").replace(/^```/g, "").replace(/```$/g, "").trim();

                                    const parsedToolCall = JSON.parse(jsonStr);
                                    if (parsedToolCall.name) {
                                        finalFunctionCall = parsedToolCall;
                                        isAsyncParsedTool = true;
                                        console.log("[Async Tool Parser] Successfully extracted tool call from text:", finalFunctionCall);
                                    }
                                }
                            } catch (e) {
                                console.error("[Async Tool Parser Error]", e, "Could not parse JSON block from text.");
                            }
                        }
                    }
                    // ----------------------------------------------------------------------------------------------------------

                    if (finalFunctionCall) {
                        // Function Call Received
                        let functionLogMsg = '';
                        let uiDisplayMsg = '';

                        // Extract any conversational text the AI generated *before* the tool block
                        let textBeforeTool = "";
                        if (isAsyncParsedTool && accumulatedText) {
                            const startIdx = accumulatedText.indexOf("===BEGIN_TOOL_CALL===");
                            if (startIdx > 0) {
                                textBeforeTool = accumulatedText.substring(0, startIdx).trim();
                            }
                        }

                        // Visually add the AI's internal decision to the chat
                        // If there is text before the tool, show it. Otherwise, it's just a tool call.
                        addMessage('ai', textBeforeTool, sessionId, finalFunctionCall, finalRawParts, accumulatedThought || undefined);

                        // Clear streaming state during background execution to prevent UI duplicate thoughts
                        setIsStreaming(false);
                        setStreamingText('');
                        setStreamingThought('');


                        if (finalFunctionCall.name === 'search_web') {
                            const args = finalFunctionCall.args;
                            const query = args.query;
                            addMessage('system', sessionLang === 'ja' ? `„Ç¶„Çß„Éñ„Åß„Äå${query}„Äç„ÇíÊ§úÁ¥¢„Åó„Å¶„ÅÑ„Åæ„Åô...` : `Searching the web for "${query}"...`, sessionId);
                            try {
                                const { callGeminiSearch } = await import('../../utils/gemini');
                                const searchResult = await callGeminiSearch(apiKey, query, aiModel as any);

                                // Show the short completion notification first
                                addMessage('system', sessionLang === 'ja' ? `„Äå${query}„Äç„ÅÆÊ§úÁ¥¢ÁµêÊûú„ÇíÂèñÂæó„Åó„Åæ„Åó„Åü„ÄÇ` : `Got search results for "${query}".`, sessionId);

                                functionLogMsg = `[Search Results for "${query}"]\n${searchResult}`;
                                uiDisplayMsg = `üîç **Google Search Results (${query})**\n\n${searchResult}`;
                            } catch (e: any) {
                                functionLogMsg = `[Search Error] ${e.message}`;
                                uiDisplayMsg = sessionLang === 'ja' ? `Ê§úÁ¥¢„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü„ÄÇ` : `Search error occurred.`;
                            }
                        } else if (finalFunctionCall.name === 'insert_womb_instruction') {
                            const args = finalFunctionCall.args;
                            const instructionText = args.instruction_text;
                            const event = new CustomEvent('womb:insert-instruction', { detail: { instructionText } });
                            window.dispatchEvent(event);

                            functionLogMsg = sessionLang === 'ja' ? '„Ç∑„Çπ„ÉÜ„É†: WOMB„Å´„Ç§„É≥„Çπ„Éà„É©„ÇØ„Ç∑„Éß„É≥„ÇíË®òËø∞„Åó„Åæ„Åó„Åü„ÄÇ„ÉÑ„Éº„É´Âëº„Å≥Âá∫„Åó„ÅåÁµÇ„Çè„Å£„Åü„ÇâÁü≠„ÅÑ„ÉÜ„Ç≠„Çπ„Éà„ÅßÂÆå‰∫Ü„ÇíÂ†±Âëä„Åó„Å¶„Çø„Éº„É≥„ÇíÁµÇ‰∫Ü„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ' : 'System: Inserted instruction into WOMB. Report completion if no other tools are needed.';
                            uiDisplayMsg = sessionLang === 'ja' ? 'WOMB„Å´„Ç§„É≥„Çπ„Éà„É©„ÇØ„Ç∑„Éß„É≥„ÇíË®òËø∞„Åó„Åæ„Åó„Åü„ÄÇ' : 'Inserted instruction into WOMB.';
                        } else if (finalFunctionCall.name === 'add_womb_history') {
                            const args = finalFunctionCall.args;
                            const entityQuery = args.entity_query || args.entityQuery || args.entity_name || args.entityName;
                            const explicitlyProvidedId = args.entity_id || args.entityId;
                            const historyText = args.history_text || args.historyText || args.history;

                            let isResolved = false;
                            let targetEntityId = explicitlyProvidedId || "";
                            let targetEntityName = "‰∏çÊòé„Å™„Ç≠„É£„É©„ÇØ„Çø„Éº";
                            let storyTitle = "ÂêçÁß∞Êú™Ë®≠ÂÆö„ÅÆ„Çπ„Éà„Éº„É™„Éº";

                            if (getWombContext) {
                                try {
                                    const wombContext = await getWombContext();
                                    if (wombContext.storyTitle) storyTitle = wombContext.storyTitle;

                                    if (targetEntityId && wombContext.allLoreItems) {
                                        const matchedById = wombContext.allLoreItems.find((item: any) => item.id === targetEntityId);
                                        if (matchedById) {
                                            isResolved = true;
                                            targetEntityName = matchedById.name;
                                            functionLogMsg = sessionLang === 'ja'
                                                ? `[System] Success. History added to "${matchedById.name}" (ID: ${matchedById.id}).\n„Ç∑„Çπ„ÉÜ„É†: „Éí„Çπ„Éà„É™„Éº„Å∏„ÅÆËøΩÂä†„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü„ÄÇ„Åì„Çå‰ª•‰∏ä„ÅÆ„ÉÑ„Éº„É´„ÅÆÂëº„Å≥Âá∫„Åó„ÅØ‰∏çË¶Å„Åß„Åô„ÄÇ„Äå${matchedById.name}„ÅÆ„Éí„Çπ„Éà„É™„Éº„Å´ËøΩÂä†„Åó„Åæ„Åó„Åü„Äç„Å®„ÉÜ„Ç≠„Çπ„ÉàÂá∫Âäõ„Åó„Å¶„Çø„Éº„É≥„ÇíÁµÇ‰∫Ü„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ`
                                                : `[System] Success. History added to "${matchedById.name}" (ID: ${matchedById.id}).\nSystem: History addition complete. No further tool calls are needed. Output a short confirmation text and end your turn.`;
                                        }
                                    }

                                    if (!isResolved && wombContext.allLoreItems && entityQuery) {
                                        const allItems = wombContext.allLoreItems;
                                        const activeItems = wombContext.allActiveLoreItems || [];
                                        const queryLower = entityQuery.toLowerCase();
                                        const searchData = (item: any) => item.name.toLowerCase().includes(queryLower) || (item.keywords && item.keywords.some((kw: string) => kw.toLowerCase().includes(queryLower)));

                                        let matches = activeItems.filter(searchData);
                                        if (matches.length === 0) matches = allItems.filter(searchData);

                                        if (matches.length === 1) {
                                            targetEntityId = matches[0].id;
                                            targetEntityName = matches[0].name;
                                            isResolved = true;
                                            functionLogMsg = sessionLang === 'ja'
                                                ? `[System] Success. History added to "${matches[0].name}" (ID: ${matches[0].id}).\n„Ç∑„Çπ„ÉÜ„É†: „Éí„Çπ„Éà„É™„Éº„Å∏„ÅÆËøΩÂä†„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü„ÄÇ„Åì„Çå‰ª•‰∏ä„ÅÆ„ÉÑ„Éº„É´„ÅÆÂëº„Å≥Âá∫„Åó„ÅØ‰∏çË¶Å„Åß„Åô„ÄÇ„Äå${matches[0].name}„ÅÆ„Éí„Çπ„Éà„É™„Éº„Å´ËøΩÂä†„Åó„Åæ„Åó„Åü„Äç„Å®„ÉÜ„Ç≠„Çπ„ÉàÂá∫Âäõ„Åó„Å¶„Çø„Éº„É≥„ÇíÁµÇ‰∫Ü„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ`
                                                : `[System] Success. History added to "${matches[0].name}" (ID: ${matches[0].id}).\nSystem: History addition complete. No further tool calls are needed. Output a short confirmation text and end your turn.`;
                                        } else if (matches.length > 1) {
                                            const candidatesStr = matches.map((m: any) => `- ID: ${m.id}, Name: ${m.name}`).join('\n');
                                            functionLogMsg = `[System] Error: Ambiguous target. Multiple characters match the query "${entityQuery}".\nCandidates:\n${candidatesStr}\n\nPlease ask the user to clarify which ID they meant.`;
                                        } else {
                                            const { getLevenshteinDistance } = await import('../../utils/bison');
                                            const scoredItems = allItems.map((item: any) => ({ item, distance: getLevenshteinDistance(queryLower, item.name.toLowerCase()) })).sort((a: any, b: any) => a.distance - b.distance);
                                            const closestStr = scoredItems.slice(0, 3).map((s: any) => `- ID: ${s.item.id}, Name: ${s.item.name}`).join('\n');
                                            functionLogMsg = `[System] Error: Target not found. No character perfectly matches "${entityQuery}".\nDid the user mean one of these?\nCandidates:\n${closestStr}\n\nPlease ask the user if they meant one of these characters.`;
                                        }
                                    }
                                } catch (e) {
                                    functionLogMsg = `[System] Error: Failed to query database.`;
                                }
                            } else {
                                if (explicitlyProvidedId) {
                                    targetEntityId = explicitlyProvidedId;
                                    isResolved = true;
                                    functionLogMsg = sessionLang === 'ja'
                                        ? `[System] Success. Executed with provided ID.\n„Ç∑„Çπ„ÉÜ„É†: „Éí„Çπ„Éà„É™„Éº„Å∏„ÅÆËøΩÂä†„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü„ÄÇ„Åì„Çå‰ª•‰∏ä„ÅÆ„ÉÑ„Éº„É´„ÅÆÂëº„Å≥Âá∫„Åó„ÅØ‰∏çË¶Å„Åß„Åô„ÄÇÂÆå‰∫Ü„Åó„ÅüÊó®„Çí„ÉÜ„Ç≠„Çπ„ÉàÂá∫Âäõ„Åó„Å¶„Çø„Éº„É≥„ÇíÁµÇ‰∫Ü„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ`
                                        : `[System] Success. Executed with provided ID.\nSystem: History addition complete. No further tool calls are needed. Output a short confirmation text and end your turn.`;
                                }
                            }

                            uiDisplayMsg = functionLogMsg;
                            if (isResolved && targetEntityId) {
                                const event = new CustomEvent('womb:add-history', { detail: { entityId: targetEntityId, historyText } });
                                window.dispatchEvent(event);
                                uiDisplayMsg = `${targetEntityName}(${targetEntityId})„ÅÆ„Éí„Çπ„Éà„É™„Éº„Å´ËøΩË®ò„Åó„Åæ„Åó„Åü(${storyTitle})`;
                            }
                        } else if (finalFunctionCall.name === 'trigger_auto_history') {
                            if (hasTriggeredAutoHistory) {
                                functionLogMsg = sessionLang === 'ja'
                                    ? "„Ç∑„Çπ„ÉÜ„É†„Ç®„É©„Éº: „Åô„Åß„Å´„Åì„ÅÆ„Çø„Éº„É≥„ÅßÊäΩÂá∫„ÇíÂÆüË°åÊ∏à„Åß„Åô„ÄÇÁü≠„ÅÑÂÆå‰∫ÜÂøúÁ≠î„ÇíÂá∫Âäõ„Åó„Å¶ÁµÇ‰∫Ü„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
                                    : "System Error: Extraction already triggered. Output a short confirmation text and end your turn.";
                            } else if (triggerAutoHistory) {
                                hasTriggeredAutoHistory = true;
                                triggerAutoHistory();
                                functionLogMsg = sessionLang === 'ja' ? "„Ç∑„Çπ„ÉÜ„É†: Ëá™Âãï„Éí„Çπ„Éà„É™„ÉºÊäΩÂá∫„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„ÄÇ„Åì„Çå‰ª•‰∏ä„ÅÆ„ÉÑ„Éº„É´Âëº„Å≥Âá∫„Åó„ÅØ‰∏çË¶Å„Åß„Åô„ÄÇ„Äå„Éí„Çπ„Éà„É™„Éº„ÅÆÊäΩÂá∫„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„Äç„Å®„ÉÜ„Ç≠„Çπ„ÉàÂá∫Âäõ„Åó„Å¶„Çø„Éº„É≥„ÇíÁµÇ‰∫Ü„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ" : "System: Started automatic history extraction. No further tool calls are needed. Output a short confirmation text and end your turn.";
                            } else {
                                functionLogMsg = "[System Error] triggerAutoHistory is not available.";
                            }
                            uiDisplayMsg = sessionLang === 'ja' ? "Êú¨Êñá„Åã„Çâ„ÅÆËá™Âãï„Éí„Çπ„Éà„É™„ÉºÊäΩÂá∫Âá¶ÁêÜ„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„ÄÇÂ§âÊõ¥„Åå„ÅÇ„Å£„ÅüÂ†¥Âêà„ÅØ„Åæ„ÇÇ„Å™„ÅèÂèçÊò†„Åï„Çå„Åæ„Åô„ÄÇ" : "Started automatic history extraction from the text. Changes will be reflected shortly if any are found.";
                        } else if (finalFunctionCall.name === 'trigger_womb_generation') {
                            if (hasTriggeredWomb) {
                                functionLogMsg = sessionLang === 'ja'
                                    ? "„Ç∑„Çπ„ÉÜ„É†„Ç®„É©„Éº: „Åô„Åß„Å´„Åì„ÅÆ„Çø„Éº„É≥„ÅßWOMB„Çí„Éà„É™„Ç¨„Éº„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„Çå‰ª•‰∏ä„ÅÆ„ÉÑ„Éº„É´Âëº„Å≥Âá∫„Åó„ÅØ‰∏çË¶Å„Åß„Åô„ÄÇ„ÄåÁîüÊàê„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„Äç„Å™„Å©„ÅÆÁü≠„ÅÑ„ÉÜ„Ç≠„Çπ„Éà„ÇíËøîÁ≠î„Åó„Å¶ÁµÇ‰∫Ü„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
                                    : "System Error: WOMB already triggered. Output a short confirmation text and end your turn.";
                                uiDisplayMsg = functionLogMsg;
                            } else if (triggerWombGeneration) {
                                hasTriggeredWomb = true;
                                const blueprintText = finalFunctionCall.args?.blueprint_text || accumulatedText;

                                if (aiModel === 'glm-4-6') {
                                    // GLM-4 specific: Wait for WOMB to finish before acknowledging the tool
                                    // This completely prevents 429 concurrent limit errors on NovelAI.
                                    addMessage('system', sessionLang === 'ja' ? "WOMB„Åß„ÅÆËá™ÂãïÁîüÊàêÂÆå‰∫Ü„ÇíÂæÖÊ©ü„Åó„Å¶„ÅÑ„Åæ„Åô..." : "Waiting for WOMB generation to complete...", sessionId);

                                    await triggerWombGeneration(blueprintText);

                                    // Wait for Auto-History to finish if it got triggered by the generation save process
                                    if (checkIsBackgroundProcessing) {
                                        // Give the WOMB save process a tiny head start to sync state (evaluateBackgroundTrigger)
                                        await new Promise(resolve => setTimeout(resolve, 500));

                                        if (checkIsBackgroundProcessing()) {
                                            console.log("[CORD] Waiting for background auto-history extraction to complete...");
                                            addMessage('system', sessionLang === 'ja' ? "ËÉåÊôØ„Åß„ÅÆËá™Âãï„Éí„Çπ„Éà„É™„ÉºÊäΩÂá∫„ÅÆÂÆå‰∫Ü„ÇíÂæÖÊ©ü„Åó„Å¶„ÅÑ„Åæ„Åô..." : "Waiting for background auto-history extraction...", sessionId);
                                            while (checkIsBackgroundProcessing()) {
                                                await new Promise(resolve => setTimeout(resolve, 1500));
                                            }
                                        }
                                    }

                                    functionLogMsg = sessionLang === 'ja'
                                        ? "„Ç∑„Çπ„ÉÜ„É†: WOMB„Åß„ÅÆÊú¨ÊñáÁîüÊàê„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü„ÄÇ„Åì„Çå‰ª•‰∏ä„ÅÆÊìç‰Ωú„ÅØ‰∏çË¶Å„Åß„Åô„ÄÇ„ÄåÁîüÊàê„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü„ÄçÁ≠â„ÅÆÁü≠„ÅÑ„ÉÜ„Ç≠„Çπ„Éà„ÇíËøîÁ≠î„Åó„Å¶„Çø„Éº„É≥„ÇíÁµÇ‰∫Ü„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
                                        : "System: WOMB generation has completed. No further tool calls are needed. Output a short confirmation text and end your turn.";
                                    uiDisplayMsg = sessionLang === 'ja' ? "WOMB„Åß„ÅÆÊú¨ÊñáÁîüÊàê„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü„ÄÇ" : "WOMB generation completed.";
                                } else {
                                    // Gemini specific: Fire and forget
                                    triggerWombGeneration(blueprintText);

                                    // Wait for Auto-History to finish if it got triggered by the generation save process
                                    if (checkIsBackgroundProcessing) {
                                        // Give the WOMB save process a tiny head start to sync state (evaluateBackgroundTrigger)
                                        await new Promise(resolve => setTimeout(resolve, 500));

                                        if (checkIsBackgroundProcessing()) {
                                            console.log("[CORD] Waiting for background auto-history extraction to complete...");
                                            addMessage('system', sessionLang === 'ja' ? "ËÉåÊôØ„Åß„ÅÆËá™Âãï„Éí„Çπ„Éà„É™„ÉºÊäΩÂá∫„ÅÆÂÆå‰∫Ü„ÇíÂæÖÊ©ü„Åó„Å¶„ÅÑ„Åæ„Åô..." : "Waiting for background auto-history extraction...", sessionId);
                                            while (checkIsBackgroundProcessing()) {
                                                await new Promise(resolve => setTimeout(resolve, 1500));
                                            }
                                        }
                                    }

                                    functionLogMsg = sessionLang === 'ja'
                                        ? "„Ç∑„Çπ„ÉÜ„É†: Narrative Blueprint„Çí‰ΩúÊàê„Åó„ÄÅWOMB„Å´ÈÄÅ‰ø°„Åó„Åæ„Åó„Åü„ÄÇ„Åì„Çå‰ª•‰∏ä„ÅÆ„ÉÑ„Éº„É´Âëº„Å≥Âá∫„Åó„ÅØ‰∏çË¶Å„Åß„Åô„ÄÇ„ÄåWOMB„Å´„Å¶ÁîüÊàê„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„Äç„Å®„ÉÜ„Ç≠„Çπ„ÉàÂá∫Âäõ„Åó„Å¶„Çø„Éº„É≥„ÇíÁµÇ‰∫Ü„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
                                        : "System: The Narrative Blueprint is created and sent to WOMB. No further tool calls are needed. Output a short text like '[Generating in WOMB]' to end your turn.";
                                    uiDisplayMsg = sessionLang === 'ja' ? "Narrative Blueprint„Çí‰ΩúÊàê„Åó„ÄÅWOMB„Å´ÈÄÅ‰ø°„Åó„Åæ„Åó„Åü„ÄÇ" : "The Narrative Blueprint is created and sent to WOMB.";
                                }
                            } else {
                                functionLogMsg = "[System Error] triggerWombGeneration is not available.";
                                uiDisplayMsg = functionLogMsg;
                            }
                        } else {
                            // Unknown function
                            functionLogMsg = `[System] Unknown function called: ${finalFunctionCall.name}`;
                            uiDisplayMsg = functionLogMsg;
                        }

                        // Prepare function response and update message history for the next loop
                        const funcCallMsg: ChatMessageData = {
                            role: 'ai',
                            // For GLM-4, store ONLY the conversational part of the text so the system remembers the AI spoke
                            content: textBeforeTool,
                            functionCall: finalFunctionCall,
                            rawParts: isAsyncParsedTool ? [{ text: textBeforeTool }] : finalRawParts
                        };
                        const funcResMsg: ChatMessageData = {
                            role: 'function',
                            content: functionLogMsg,
                            functionCall: { name: finalFunctionCall.name, args: {} }
                        };

                        addMessage('function', uiDisplayMsg, sessionId, { name: finalFunctionCall.name, args: {} });
                        currentApiMessages = [...currentApiMessages, funcCallMsg as any, funcResMsg as any];

                        // loop continues!
                    } else if (accumulatedText || accumulatedThought) {
                        // AI finished with text
                        const finalText = accumulatedText ? accumulatedText.trimStart() : '';
                        addMessage('ai', finalText, sessionId, undefined, finalRawParts, accumulatedThought || undefined);

                        // Clear streaming state immediately before any background processing
                        setIsStreaming(false);
                        setStreamingText('');
                        setStreamingThought('');

                        // --- Auto Titling Logic ---
                        if (currentMessages.length === 1 && currentMessages[0].role === 'user') {
                            const freshSessionsStr = localStorage.getItem(STORAGE_KEY_SESSIONS);
                            const freshSessions: ChatSession[] = freshSessionsStr ? JSON.parse(freshSessionsStr) : sessions;
                            const sessionToUpdate = freshSessions.find(s => s.id === sessionId);
                            if (sessionToUpdate && sessionToUpdate.title === 'New Chat') {
                                try {
                                    const titlePrompt = sessionLang === 'ja'
                                        ? `Ê¨°„ÅÆ„É¶„Éº„Ç∂„Éº„ÅÆÂÖ•Âäõ„ÇíÂÖÉ„Å´„ÄÅ„Åì„ÅÆ„ÉÅ„É£„ÉÉ„Éà„ÅÆ„Çø„Ç§„Éà„É´„Çí20ÊñáÂ≠ó‰ª•ÂÜÖ„Åß‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n‚Äª„Äå(„Äá„ÄáÊñáÂ≠ó)„Äç„ÅÆ„Çà„ÅÜ„Å™ÊñáÂ≠óÊï∞„ÅÆ„Ç´„Ç¶„É≥„Éà„ÇÑ„Ç´„ÉÉ„Ç≥„Å™„Å©„ÅÆË£úË∂≥ÊÉÖÂ†±„ÅØ‰∏ÄÂàáÂê´„ÇÅ„Åö„ÄÅÁ¥îÁ≤ã„Å™„Çø„Ç§„Éà„É´ÊñáÂ≠óÂàó„ÅÆ„Åø„ÇíÂá∫Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n\n„É¶„Éº„Ç∂„ÉºÂÖ•Âäõ: "${currentMessages[0].content}"`
                                        : `Create a title for this chat based on the following user input. Keep it under 20 characters.\n* Output ONLY the pure title string without quotes, parentheses, or character counts.\n\nUser input: "${currentMessages[0].content}"`;

                                    const generatedTitle = await callGemini(apiKey, titlePrompt, 'gemini-2.5-flash');
                                    const cleanTitle = generatedTitle.replace(/["']/g, '').trim();

                                    const updatedSessions = freshSessions.map(s => s.id === sessionId ? { ...s, title: cleanTitle } : s);
                                    saveSessionsToStorage(updatedSessions);
                                } catch (titleError) {
                                    console.error("Failed to generate title:", titleError);
                                }
                            }
                        }
                        break; // Exit the loop successfully
                    } else {
                        break; // Edge case, exit to prevent infinite loop
                    }
                }
            } finally {
                setIsStreaming(false);
            }

        } catch (error: any) {
            console.error("CORD AI Generate Error:", error);
            const fallbackLang = lang;
            // Fallback to mock on API Error (e.g., invalid key)
            const responseText = fallbackLang === 'ja'
                ? '„Å™„Çã„Åª„Å©„ÄÅ„Åù„Çå„ÅØËààÂë≥Ê∑±„ÅÑ„Åß„Åô„Å≠„ÄÇÔºà‚ÄªAPIÈÄö‰ø°„Ç®„É©„Éº„ÅÆ„Åü„ÇÅ„É¢„ÉÉ„ÇØÂøúÁ≠î„Åß„ÅôÔºâ'
                : 'I see, that sounds interesting. (Mock response due to API error)';
            addMessage('ai', responseText, sessionId);
        } finally {
            setIsTyping(false);
        }
    };

    return {
        isTyping,
        isStreaming,
        streamingText,
        streamingThought,
        generateAiResponse
    };
};
