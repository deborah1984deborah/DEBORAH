import { useState } from 'react';
import { ChatSession, ChatMessage } from '../../types';
import { ChatMessageData } from '../../utils/gemini';
import { getBaseSystemPrompt, getGlmToolPrompt } from './generation/cordPrompts';
import { getCordTools } from './generation/cordTools';
import { handleCordToolCall } from './generation/cordToolHandlers';
import { parseAsyncToolResponse } from './generation/parseAsyncToolResponse';
import { UseCordGenerationProps } from './generation/types';

export const useCordGeneration = ({
    lang,
    sessions,
    messages,
    addMessage,
    cordDebug,
    STORAGE_KEY_SESSIONS,
    STORAGE_KEY_MESSAGES_PREFIX,
    saveSessionsToStorage,
    triggerAutoHistory,
    triggerWombGeneration,
    cordOutputLength,
    checkIsBackgroundProcessing,
    isPseudoThinkingModeEnabled
}: UseCordGenerationProps) => {
    const [isTyping, setIsTyping] = useState<boolean>(false);
    const [isStreaming, setIsStreaming] = useState<boolean>(false);
    const [streamingText, setStreamingText] = useState<string>('');
    const [streamingThought, setStreamingThought] = useState<string>('');

    // Action: Generate AI Response
    const generateAiResponse = async (
        sessionId: string,
        apiKey: string,
        novelAIApiKey: string,
        aiModel: 'gemini-2.5-flash' | 'gemini-3.1-pro-preview' | 'glm-4-6',
        getWombContext?: () => Promise<{ systemInstruction: string, entityContext?: string, scanTargetContent?: string, matchedLoreItems: any[], allActiveLoreItems: any[], allLoreItems: any[], cleanedContent: string, storyTitle: string }>,
        isAutoGenerated: boolean = false
    ) => {
        if (!apiKey && !novelAIApiKey) {
            // Fallback mock if no API key
            setIsTyping(true);
            setTimeout(() => {
                const responseText = lang === 'ja'
                    ? 'なるほど、それは興味深いですね。（※APIキーが未設定のためモック応答です）'
                    : 'I see, that sounds interesting. (Mock response due to missing API key)';
                addMessage('ai', responseText, sessionId);
                setIsTyping(false);
            }, 1000);
            return;
        }

        setIsTyping(true);
        try {
            const { callGeminiChatStream, callGemini } = await import('../../utils/gemini');

            // Get latest messages for this session from state/localStorage
            const storedMessages = localStorage.getItem(STORAGE_KEY_MESSAGES_PREFIX + sessionId);
            const currentMessages: ChatMessage[] = storedMessages ? JSON.parse(storedMessages) : messages;

            const freshSessionsStrForCheck = localStorage.getItem(STORAGE_KEY_SESSIONS);
            const freshCurrentSessions: ChatSession[] = freshSessionsStrForCheck ? JSON.parse(freshSessionsStrForCheck) : sessions;
            const currentSession = freshCurrentSessions.find(s => s.id === sessionId);

            const sessionLang = currentSession?.aiLang || lang;

            let systemPrompt = getBaseSystemPrompt(sessionLang);

            let wombContextString = "";
            if (currentSession?.isAwareOfWombStory && getWombContext) {
                try {
                    const wombContext = await getWombContext();
                    if (wombContext) {
                        wombContextString += `[System Info: Current WOMB Story Context]\n`;
                        if (wombContext.entityContext) {
                            wombContextString += `--- Matched Entities ---\n${wombContext.entityContext}\n\n`;
                        }

                        if (wombContext.cleanedContent) {
                            wombContextString += `--- Story Body Text ---\n${wombContext.cleanedContent}`;
                        }

                        // Set matched entities for debug panel
                        cordDebug.setCordDebugMatchedEntities(wombContext.matchedLoreItems || []);
                    }
                } catch (e) {
                    console.error("Failed to load WOMB context for CORD", e);
                }
            }

            // Assemble final array for API call
            const apiMessages = [...currentMessages];

            // Loop backwards to find the last user message to inject context and constraints
            for (let i = apiMessages.length - 1; i >= 0; i--) {
                if (apiMessages[i].role === 'user') {
                    const originalInput = apiMessages[i].content;

                    // 1. Construct Output Length Constraint for CORD
                    const lengthConstraint = sessionLang === 'ja'
                        ? `\n\n【出力形式の制約】\nあなたの返答テキストは、全体で大体 ${cordOutputLength} 文字以内になるように調整してください。`
                        : `\n\n[Output Constraints]\nAdjust the character count of your response to be roughly within ${cordOutputLength} characters.`;

                    // Only append WOMB Context if it exists
                    const userInputHeader = wombContextString ? `${wombContextString}${lengthConstraint}\n\n=== User Input ===\n` : `${lengthConstraint}\n\n=== User Input ===\n`;

                    // 2. Pseudo-Thinking Injection (Phase 1)
                    // Only inject if it's GLM, pseudo-thinking is enabled, and it's NOT an auto-generated (background/system) request
                    let pseudoThinkingInstruction = "";
                    if (aiModel === 'glm-4-6' && isPseudoThinkingModeEnabled && !isAutoGenerated) {
                        pseudoThinkingInstruction = sessionLang === 'ja'
                            ? `\n\n【指示】\nユーザーからのメッセージに対応するために、事前に段階的かつ論理的に対応方法について思考しましょう。思考プロセスをテキスト出力し、思考が完了したら最後に「[THINKING_COMPLETE]」と出力してください。`
                            : `\n\n[Instruction]\nTo respond to the user's message, please think step-by-step and logically beforehand. Output your thought process, and once your thinking is complete, output "[THINKING_COMPLETE]" at the end.`;
                    }

                    apiMessages[i] = {
                        ...apiMessages[i],
                        content: userInputHeader + originalInput + pseudoThinkingInstruction
                    };
                    break;
                }
            }

            // Define tools for CORD
            const cordTools = getCordTools(sessionLang);

            // [HACK] For GLM-4 model which ignores tool definitions in the system param,
            // we manually append the tool descriptions and formatting rules into the system prompt.
            if (aiModel === 'glm-4-6') {
                systemPrompt += getGlmToolPrompt(sessionLang);
            }

            // Update Debug State visually
            let lastUserInput = "";
            for (let i = apiMessages.length - 1; i >= 0; i--) {
                if (apiMessages[i].role === 'user') {
                    lastUserInput = apiMessages[i].content;
                    break;
                }
            }
            cordDebug.setCordDebugSystemPrompt(systemPrompt);
            cordDebug.setCordDebugInputText(lastUserInput);

            // Call Chat API with Streaming, loop for multi-turn function calls
            setIsStreaming(true);
            setStreamingText('');
            setStreamingThought('');

            let currentApiMessages = [...apiMessages];
            let loopCount = 0;
            const MAX_LOOPS = 5;
            let hasTriggeredWomb = false;
            let hasTriggeredAutoHistory = false;

            // Pseudo-Thinking State Tracking
            let activePseudoThought = "";
            let isIteratingPseudoThought = aiModel === 'glm-4-6' && isPseudoThinkingModeEnabled && !isAutoGenerated;

            if (isIteratingPseudoThought) {
                console.log("[CORD] ✨ Pseudo-Thinking Mode: PHASE 1 (Thinking) Started.");
            }

            try {
                while (loopCount < MAX_LOOPS) {
                    loopCount++;
                    let accumulatedText = '';
                    let accumulatedThought = '';
                    let finalFunctionCall: any = undefined;
                    let finalRawParts: any[] = [];

                    if (loopCount > 1) {
                        setIsStreaming(true);
                        setStreamingText('');
                        setStreamingThought('');
                    }

                    let abortController: AbortController | undefined;
                    let stream;
                    if (aiModel === 'glm-4-6') {
                        const { callNovelAIChatStream } = await import('../../utils/novelai');
                        abortController = new AbortController();
                        // tools are ignored in NovelAI for now
                        stream = callNovelAIChatStream(novelAIApiKey, currentApiMessages as any, aiModel, systemPrompt, abortController.signal);
                    } else {
                        stream = callGeminiChatStream(apiKey, currentApiMessages as any, aiModel as any, systemPrompt, cordTools);
                    }

                    for await (const chunk of stream) {
                        if (chunk.textChunk) {
                            if (isIteratingPseudoThought) {
                                // --- Pseudo-Thinking Phase 1 (Thinking) ---
                                accumulatedThought += chunk.textChunk;
                                setStreamingThought(accumulatedThought.replace(/\[THINKING_COMPLETE\]/g, "").trimStart());

                                if (accumulatedThought.includes("[THINKING_COMPLETE]")) {
                                    if (abortController) abortController.abort();
                                    break;
                                }
                            } else {
                                // --- Standard Output Phase ---
                                accumulatedText += chunk.textChunk;
                                // Remove leading newlines/spaces that some models (like GLM) might return
                                setStreamingText(accumulatedText.trimStart());

                                // Abort streaming early if tool call block is finished
                                if (aiModel === 'glm-4-6' && accumulatedText.includes("===END_TOOL_CALL===")) {
                                    if (abortController) abortController.abort();
                                    break;
                                }
                            }
                        }
                        if (chunk.thoughtChunk) {
                            accumulatedThought += chunk.thoughtChunk;
                            setStreamingThought(accumulatedThought);
                        }
                        if (chunk.functionCall) {
                            finalFunctionCall = chunk.functionCall;
                        }
                        if (chunk.rawParts && chunk.rawParts.length > 0) {
                            finalRawParts = chunk.rawParts;
                        }
                    }

                    // --- Phase Transition (Phase 1 -> Phase 2) ---
                    if (isIteratingPseudoThought) {
                        activePseudoThought = accumulatedThought.replace(/\[THINKING_COMPLETE\]/g, "").trim();
                        isIteratingPseudoThought = false;

                        // Inject Phase 2 implicit user query
                        const phase2Instruction = sessionLang === 'ja'
                            ? `\n\n思考が完了しました。思考した内容をベースに、ユーザーからのメッセージへ本回答を行ってください。`
                            : `\n\nThinking is complete. Now, based on your thoughts, please provide the final response to the user's message.`;

                        // We must append the AI's thought into the history so it can "see" what it just thought
                        currentApiMessages.push({ role: 'ai', content: activePseudoThought } as any);
                        currentApiMessages.push({ role: 'user', content: phase2Instruction } as any);

                        console.log("[CORD] ✨ Pseudo-Thinking Mode: PHASE 1 Complete. Transitioning to PHASE 2 (Response).");
                        console.log("[CORD] Intercepted Thought:", activePseudoThought);
                        continue; // Trigger the next API call immediately
                    }

                    // --- Post-Streaming Async Tool Parsing (Fallback logic specifically for models without native tool call like NovelAI) ---
                    let isAsyncParsedTool = false; // Flag to stop recursive loops
                    let textBeforeTool = "";       // Extracted text before the tool block

                    if (!finalFunctionCall && accumulatedText) {
                        const parsed = parseAsyncToolResponse(accumulatedText);
                        if (parsed.finalFunctionCall) {
                            finalFunctionCall = parsed.finalFunctionCall;
                            isAsyncParsedTool = true;
                            if (parsed.textBeforeTool) {
                                textBeforeTool = parsed.textBeforeTool;
                            }
                        }
                    }
                    // ----------------------------------------------------------------------------------------------------------

                    if (finalFunctionCall) {
                        // Function Call Received
                        let functionLogMsg = '';
                        let uiDisplayMsg = '';

                        // Extracted conversational text the AI generated *before* the tool block is already in `textBeforeTool`

                        // Visually add the AI's internal decision to the chat
                        // If there is text before the tool, show it. Otherwise, it's just a tool call.
                        addMessage('ai', textBeforeTool, sessionId, finalFunctionCall, finalRawParts, accumulatedThought || undefined);

                        // Clear streaming state during background execution to prevent UI duplicate thoughts
                        setIsStreaming(false);
                        setStreamingText('');
                        setStreamingThought('');


                        const handlerResult = await handleCordToolCall({
                            finalFunctionCall,
                            sessionLang,
                            sessionId,
                            aiModel,
                            apiKey: apiKey || novelAIApiKey || '',
                            accumulatedText,
                            hasTriggeredAutoHistory,
                            hasTriggeredWomb,
                            addMessage,
                            triggerAutoHistory,
                            triggerWombGeneration,
                            checkIsBackgroundProcessing,
                            getWombContext
                        });

                        functionLogMsg = handlerResult.functionLogMsg;
                        uiDisplayMsg = handlerResult.uiDisplayMsg;
                        hasTriggeredAutoHistory = handlerResult.hasTriggeredAutoHistory;
                        hasTriggeredWomb = handlerResult.hasTriggeredWomb;

                        // Prepare function response and update message history for the next loop
                        const funcCallMsg: ChatMessageData = {
                            role: 'ai',
                            // For GLM-4, store ONLY the conversational part of the text so the system remembers the AI spoke
                            content: textBeforeTool,
                            functionCall: finalFunctionCall,
                            rawParts: isAsyncParsedTool ? [{ text: textBeforeTool }] : finalRawParts
                        };
                        const funcResMsg: ChatMessageData = {
                            role: 'function',
                            content: functionLogMsg,
                            functionCall: { name: finalFunctionCall.name, args: {} }
                        };

                        addMessage('function', uiDisplayMsg, sessionId, { name: finalFunctionCall.name, args: {} });
                        currentApiMessages = [...currentApiMessages, funcCallMsg as any, funcResMsg as any];

                        // loop continues!
                    } else if (accumulatedText || accumulatedThought || isIteratingPseudoThought) {
                        // AI finished with text
                        const finalText = accumulatedText ? accumulatedText.trimStart() : '';
                        // Extract any conversational text the AI generated *before* the tool block (if applicable)
                        let textBeforeTool = "";
                        if (isAsyncParsedTool && accumulatedText) {
                            const parsed = parseAsyncToolResponse(accumulatedText);
                            if (parsed.textBeforeTool) {
                                textBeforeTool = parsed.textBeforeTool;
                            }
                        }

                        const actualTextContent = textBeforeTool || accumulatedText;
                        const finalThoughtSummary = activePseudoThought || (accumulatedThought || undefined);

                        if (finalText && actualTextContent) {
                            addMessage('ai', finalText, sessionId, undefined, finalRawParts, finalThoughtSummary);
                        } else if (actualTextContent) {
                            // Even if no specific UI logic, log the final AI text response
                            addMessage('ai', actualTextContent, sessionId, undefined, finalRawParts, finalThoughtSummary);
                        } else {
                            // If literally empty message with just a thought
                            if (finalThoughtSummary) {
                                addMessage('ai', "", sessionId, undefined, finalRawParts, finalThoughtSummary);
                            }
                        }
                        // Clear streaming state immediately before any background processing
                        setIsStreaming(false);
                        setStreamingText('');
                        setStreamingThought('');

                        // --- Auto Titling Logic ---
                        if (currentMessages.length === 1 && currentMessages[0].role === 'user') {
                            const freshSessionsStr = localStorage.getItem(STORAGE_KEY_SESSIONS);
                            const freshSessions: ChatSession[] = freshSessionsStr ? JSON.parse(freshSessionsStr) : sessions;
                            const sessionToUpdate = freshSessions.find(s => s.id === sessionId);
                            if (sessionToUpdate && sessionToUpdate.title === 'New Chat') {
                                try {
                                    const titlePrompt = sessionLang === 'ja'
                                        ? `次のユーザーの入力を元に、このチャットのタイトルを20文字以内で作成してください。\n※「(〇〇文字)」のような文字数のカウントやカッコなどの補足情報は一切含めず、純粋なタイトル文字列のみを出力してください。\n\nユーザー入力: "${currentMessages[0].content}"`
                                        : `Create a title for this chat based on the following user input. Keep it under 20 characters.\n* Output ONLY the pure title string without quotes, parentheses, or character counts.\n\nUser input: "${currentMessages[0].content}"`;

                                    const generatedTitle = await callGemini(apiKey, titlePrompt, 'gemini-2.5-flash');
                                    const cleanTitle = generatedTitle.replace(/["']/g, '').trim();

                                    const updatedSessions = freshSessions.map(s => s.id === sessionId ? { ...s, title: cleanTitle } : s);
                                    saveSessionsToStorage(updatedSessions);
                                } catch (titleError) {
                                    console.error("Failed to generate title:", titleError);
                                }
                            }
                        }
                        break; // Exit the loop successfully
                    } else {
                        break; // Edge case, exit to prevent infinite loop
                    }
                }
            } finally {
                setIsStreaming(false);
            }

        } catch (error: any) {
            console.error("CORD AI Generate Error:", error);
            const fallbackLang = lang;
            // Fallback to mock on API Error (e.g., invalid key)
            const responseText = fallbackLang === 'ja'
                ? 'なるほど、それは興味深いですね。（※API通信エラーのためモック応答です）'
                : 'I see, that sounds interesting. (Mock response due to API error)';
            addMessage('ai', responseText, sessionId);
        } finally {
            setIsTyping(false);
        }
    };

    return {
        isTyping,
        isStreaming,
        streamingText,
        streamingThought,
        generateAiResponse
    };
};
